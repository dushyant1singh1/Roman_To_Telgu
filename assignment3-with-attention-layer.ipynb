{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8429589,"sourceType":"datasetVersion","datasetId":5019841}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport gc\nimport random\n# import wandb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-16T16:43:48.866670Z","iopub.execute_input":"2024-05-16T16:43:48.867450Z","iopub.status.idle":"2024-05-16T16:43:48.873343Z","shell.execute_reply.started":"2024-05-16T16:43:48.867419Z","shell.execute_reply":"2024-05-16T16:43:48.872230Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def dataLoading(src):\n    #path = \"/kaggle/input/roman-to-telgu/tel_{}.csv\".format(data_type)\n    df = pd.read_csv(src,header=None)\n    return df[0].to_numpy(), df[1].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:49.407822Z","iopub.execute_input":"2024-05-16T16:43:49.408257Z","iopub.status.idle":"2024-05-16T16:43:49.413784Z","shell.execute_reply.started":"2024-05-16T16:43:49.408227Z","shell.execute_reply":"2024-05-16T16:43:49.412753Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nMAX_LENGTH = 30\nBATCH_SIZE = 32\nEOS_token = 1\nSOS_token = 0\nPAD_token = 2\nTEACHER_FORCING_RATIO = 0.5\n\ntrain_csv = \"/kaggle/input/assignment3/tel_train.csv\"\ntest_csv = \"/kaggle/input/assignment3/tel_test.csv\"\nval_csv = \"/kaggle/input/assignment3/tel_valid.csv\"\n\ntrain_input , train_output = dataLoading(train_csv)\nvalid_input, valid_output = dataLoading(val_csv)\ntest_input, test_output = dataLoading(test_csv)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:50.366192Z","iopub.execute_input":"2024-05-16T16:43:50.366564Z","iopub.status.idle":"2024-05-16T16:43:50.562270Z","shell.execute_reply.started":"2024-05-16T16:43:50.366535Z","shell.execute_reply":"2024-05-16T16:43:50.561089Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"def characterFetching(x):\n    characters = 3\n    ind2ch ={SOS_token:'<',EOS_token:'>',PAD_token:'_'}\n    ch2ind ={'<':SOS_token,'>':EOS_token,'_':PAD_token}\n    for word in x:\n        for letter in word:\n            if letter not in ch2ind:\n                ch2ind[letter] = characters\n                ind2ch[characters] = letter\n                characters+=1\n    return [ch2ind,ind2ch,characters]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:51.159263Z","iopub.execute_input":"2024-05-16T16:43:51.159622Z","iopub.status.idle":"2024-05-16T16:43:51.166360Z","shell.execute_reply.started":"2024-05-16T16:43:51.159596Z","shell.execute_reply":"2024-05-16T16:43:51.165382Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"meta_data_input , meta_data_output = characterFetching(train_input) , characterFetching(train_output)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:52.334807Z","iopub.execute_input":"2024-05-16T16:43:52.335481Z","iopub.status.idle":"2024-05-16T16:43:52.457158Z","shell.execute_reply.started":"2024-05-16T16:43:52.335451Z","shell.execute_reply":"2024-05-16T16:43:52.456318Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def addEosPadding(x,meta_data):\n    indexed_data = []\n    for word in x:\n        l =[]\n        word += '>'\n        word += (MAX_LENGTH-len(word))*'_'\n        for char in word:\n            l.append(meta_data[0][char])\n        indexed_data.append(l)\n    return torch.tensor(indexed_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:53.140008Z","iopub.execute_input":"2024-05-16T16:43:53.140781Z","iopub.status.idle":"2024-05-16T16:43:53.146580Z","shell.execute_reply.started":"2024-05-16T16:43:53.140750Z","shell.execute_reply":"2024-05-16T16:43:53.145446Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data_tensor = DataLoader(TensorDataset(addEosPadding(train_input,meta_data_input), addEosPadding(train_output,meta_data_output)),BATCH_SIZE, shuffle = True)\nvalid_data_tensor = DataLoader(TensorDataset(addEosPadding(valid_input,meta_data_input), addEosPadding(valid_output,meta_data_output)),BATCH_SIZE, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:53.974174Z","iopub.execute_input":"2024-05-16T16:43:53.974564Z","iopub.status.idle":"2024-05-16T16:43:56.042204Z","shell.execute_reply.started":"2024-05-16T16:43:53.974537Z","shell.execute_reply":"2024-05-16T16:43:56.041343Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class Hyperparameters:\n    def __init__(self,input_dim:int,output_dim:int,\n                 encoder_layers =1,decoder_layers=1,hidden_size=64,embed_dim=512\n                 ,cell_type:str='rnn',bidirectional:bool=False,dropout:float=0,beam_search:int=0,\n                 learning_rate=0.001):\n        self.encoder_layers = encoder_layers\n        self.decoder_layers = decoder_layers\n        self.hidden_size = hidden_size\n        #input_dim is size of vocabulary of input language\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n        #output_dim is size of vocabulary of output language\n        self.output_dim = output_dim\n    \n        cell_dict = {'rnn':nn.RNN,'gru':nn.GRU,'lstm':nn.LSTM}\n        self.cell = cell_dict[cell_type]\n        self.cell_name = cell_type\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n        self.beam_search = beam_search\n        self.learning_rate = learning_rate","metadata":{"execution":{"iopub.status.busy":"2024-05-16T16:43:56.043979Z","iopub.execute_input":"2024-05-16T16:43:56.044830Z","iopub.status.idle":"2024-05-16T16:43:56.053192Z","shell.execute_reply.started":"2024-05-16T16:43:56.044793Z","shell.execute_reply":"2024-05-16T16:43:56.052267Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self,parameters:Hyperparameters):\n        super(Attention,self).__init__()\n        hidden_size = parameters.hidden_size\n        self.Wa = nn.Linear(hidden_size,hidden_size)\n        self.Ua = nn.Linear(hidden_size,hidden_size)\n        self.Va = nn.Linear(hidden_size,1)\n        \n    def forward(self,queries,keys):\n        scores = self.Va(torch.tanh(self.Wa(queries)+self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim =0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights\n    \nclass Encoder(nn.Module):\n    def __init__(self,parameters:Hyperparameters):\n        super(Encoder,self).__init__()\n        self.hidden_size = parameters.hidden_size\n        self.num_layers = parameters.encoder_layers\n        self.embedding = nn.Embedding(parameters.input_dim,parameters.embed_dim)\n        self.cell = parameters.cell(parameters.embed_dim,self.hidden_size,self.num_layers,batch_first=True)\n        self.max_length = MAX_LENGTH\n        self.batch_size = BATCH_SIZE\n        self.cell_name = parameters.cell_name\n    \n    def forward(self, input_t, current_state):\n        encoder_states = torch.zeros(self.max_length, self.num_layers, self.batch_size, self.hidden_size, device = device)\n        \n        for i in range(self.max_length):\n            current_input = input_t[:, i].view(self.batch_size,1)\n            _, current_state = self.forwardStep(current_input, current_state)\n            if self.cell_name == 'lstm':\n                encoder_states[i] = current_state[1]\n            else:\n                encoder_states[i] = current_state\n        return encoder_states, current_state\n\n    def forwardStep(self, current_input, prev_state):\n        embd_input = self.embedding(current_input)\n        output, prev_state = self.cell(embd_input, prev_state)\n        return output, prev_state\n        \n    def getInitialState(self):\n        return torch.zeros(self.num_layers, self.batch_size, self.hidden_size, device=device)\n        \n\nclass Decoder(nn.Module):\n    def __init__(self,parameters:Hyperparameters):\n        super(Decoder,self).__init__()\n        self.hidden_size = parameters.hidden_size\n        self.num_layers = parameters.decoder_layers\n        self.batch_size = BATCH_SIZE\n        self.max_length = MAX_LENGTH\n        self.cell_name = parameters.cell_name\n        self.attention = Attention(parameters)\n        self.embedding = nn.Embedding(parameters.output_dim,parameters.embed_dim)\n        self.cell = parameters.cell(parameters.embed_dim+self.hidden_size, self.hidden_size, self.num_layers, batch_first = True)\n        self.fc = nn.Linear(self.hidden_size,parameters.output_dim)\n        self.softmax = nn.LogSoftmax(dim=2)\n        \n        \n    def forward(self, current_state, encoder_final_layers, output_batch, loss_fun):\n\n        use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n        \n        decoder_input = torch.full((self.batch_size,1),SOS_token, device=device)\n        embedding = self.embedding(decoder_input)\n        soft_embed = F.relu(embedding)\n        \n        decoder_actual_output = []\n        attentions = []\n        loss = 0\n        \n\n        for i in range(self.max_length):\n            decoder_output, current_state, attn_weights = self.forwardStep(decoder_input, current_state, encoder_final_layers)\n            \n            topv, topi = decoder_output.topk(1)\n            \n            decoder_input = topi.squeeze().detach().view(self.batch_size, 1)\n            decoder_actual_output.append(decoder_input)\n\n            attentions.append(attn_weights)\n            \n            if(output_batch==None):\n                decoder_input = decoder_input.view(self.batch_size, 1)\n            else:\n                if(i<self.max_length-1):\n                    if use_teacher_forcing:\n                        decoder_current_input = output_batch[:, i+1].view(self.batch_size, 1)\n                decoder_output = decoder_output[:, -1, :]\n                loss+=(loss_fun(decoder_output, output_batch[:, i]))\n\n        decoder_actual_output = torch.cat(decoder_actual_output,dim=0).view(self.max_length, self.batch_size).transpose(0,1)\n\n        correct = (decoder_actual_output == output_batch).all(dim=1).sum().item()\n        return decoder_actual_output, attentions, loss, correct\n    \n    def forwardStep(self, current_input, prev_state, encoder_final_layers):\n        embedding = self.embedding(current_input)\n        if self.cell_name == \"lstm\":\n            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)\n        else:\n            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n        activation = F.relu(embedding)\n        \n        input_gru = torch.cat((activation, context), dim=2)\n        output, prev_state = self.cell(input_gru, prev_state)\n        output = self.softmax(self.fc(output))\n        return output, prev_state, attn_weights ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:05:52.727665Z","iopub.execute_input":"2024-05-16T17:05:52.728307Z","iopub.status.idle":"2024-05-16T17:05:52.756888Z","shell.execute_reply.started":"2024-05-16T17:05:52.728277Z","shell.execute_reply":"2024-05-16T17:05:52.755925Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, data_t, loss_fun, parameters):\n    encoder.eval()\n    decoder.eval()\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(data_t.dataset)\n    number_of_batches = len(data_t)\n    with torch.no_grad():\n        for ind, (input_tensor, output_tensor) in enumerate(data_t):\n            input_tensor  = input_tensor.to(device)\n            output_tensor = output_tensor.to(device)\n            encoder_initial = encoder.getInitialState()\n            if parameters.cell_name == \"lstm\":\n                encoder_initial = (encoder_initial, encoder.getInitialState())\n            encoder_states, encoder_final_state = encoder(input_tensor,encoder_initial)\n\n            current_state = encoder_final_state\n            encoder_final_layer_states = encoder_states[:, -1, :, :]\n\n            loss = 0\n            correct = 0\n\n            decoder_output, attentions, loss, correct = decoder(current_state, encoder_final_layer_states, output_tensor, loss_fun)\n\n            correct_predictions+=correct\n            total_loss +=loss\n\n        accuracy = correct_predictions / total_predictions\n        total_loss /= number_of_batches\n\n        return  total_loss, accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:40:22.579864Z","iopub.execute_input":"2024-05-16T17:40:22.580786Z","iopub.status.idle":"2024-05-16T17:40:22.589693Z","shell.execute_reply.started":"2024-05-16T17:40:22.580756Z","shell.execute_reply":"2024-05-16T17:40:22.588674Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"def train(parameters, encoder, decoder, train_data, valid_data, epochs ):\n\n    encoder_opt = optim.Adam(encoder.parameters(), lr = parameters.learning_rate)\n    decoder_opt = optim.Adam(decoder.parameters(), lr = parameters.learning_rate)\n    \n    loss_fun = nn.NLLLoss()\n    \n    total_predictions = len(train_data.dataset)\n    total_batches = len(train_data)\n    \n    for epoch in range(epochs):\n        encoder.train()\n        decoder.train()\n        total_correct = 0\n        total_loss = 0\n        for ind , (input_tensor, output_tensor) in enumerate(train_data):\n            input_tensor  = input_tensor.to(device)\n            output_tensor = output_tensor.to(device)\n            encoder_initial = encoder.getInitialState()\n            \n            if parameters.cell_name == 'lstm':\n                encoder_initial = (encoder_initial, encoder.getInitialState())\n            \n            encoder_states, encoder_final_state = encoder(input_tensor,encoder_initial)\n            \n            decoder_state = encoder_final_state\n            encoder_final_layer_states = encoder_states[:,-1,:,:]\n            \n            loss =0\n            correct =0\n            \n            decoder_output, attentions, loss, correct = decoder(decoder_state,encoder_final_layer_states,output_tensor,loss_fun)\n            total_correct +=correct\n            total_loss += loss.item()/MAX_LENGTH\n            \n            if(ind%30==0):\n                print(\"epoch-  \",epoch,\"batch number - \",ind, loss.item()/MAX_LENGTH,\"ACC - \",correct/BATCH_SIZE)\n            encoder_opt.zero_grad()\n            decoder_opt.zero_grad()\n            loss.backward()\n            encoder_opt.step()\n            decoder_opt.step()\n        \n        train_acc = total_correct/total_predictions\n        train_loss = total_loss/total_predictions\n        valid_loss, valid_acc = evaluate(encoder,decoder,valid_data,loss_fun,parameters)\n        print(\"Training Accuracy - \",train_acc, \"Train_loss - \",train_loss, \"Valid_acc - \", valid_acc, \"Valid_loss - \", valid_loss)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:46:38.459823Z","iopub.execute_input":"2024-05-16T17:46:38.460210Z","iopub.status.idle":"2024-05-16T17:46:38.472250Z","shell.execute_reply.started":"2024-05-16T17:46:38.460185Z","shell.execute_reply":"2024-05-16T17:46:38.471285Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"encoder_layers = 5\ndecoder_layers = 5\nhidden_size = 64\nembed_dim =256\ncell_type = 'lstm'\nbidirectional = True\ndropout = 0\nlearning_rate =0.001\ninput_dim = meta_data_input[2]\noutput_dim = meta_data_output[2]","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:46:49.206854Z","iopub.execute_input":"2024-05-16T17:46:49.207666Z","iopub.status.idle":"2024-05-16T17:46:49.212440Z","shell.execute_reply.started":"2024-05-16T17:46:49.207635Z","shell.execute_reply":"2024-05-16T17:46:49.211546Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"parameters = Hyperparameters(input_dim, output_dim, encoder_layers, decoder_layers, hidden_size, embed_dim, cell_type, bidirectional, dropout )\nencoder = Encoder(parameters).to(device)\ndecoder = Decoder(parameters).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:46:49.449822Z","iopub.execute_input":"2024-05-16T17:46:49.450711Z","iopub.status.idle":"2024-05-16T17:46:49.467577Z","shell.execute_reply.started":"2024-05-16T17:46:49.450681Z","shell.execute_reply":"2024-05-16T17:46:49.466672Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"train(parameters,encoder,decoder,train_data_tensor,valid_data_tensor,15)","metadata":{"execution":{"iopub.status.busy":"2024-05-16T17:46:51.335137Z","iopub.execute_input":"2024-05-16T17:46:51.335480Z","iopub.status.idle":"2024-05-16T17:54:57.576133Z","shell.execute_reply.started":"2024-05-16T17:46:51.335456Z","shell.execute_reply":"2024-05-16T17:54:57.574918Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"epoch-   0 batch number -  0 4.092297871907552 ACC -  0.0\nepoch-   0 batch number -  30 1.663475545247396 ACC -  0.0\nepoch-   0 batch number -  60 1.4596532185872395 ACC -  0.0\nepoch-   0 batch number -  90 1.5295500437418619 ACC -  0.0\nepoch-   0 batch number -  120 1.4103167215983072 ACC -  0.0\nepoch-   0 batch number -  150 1.3071956634521484 ACC -  0.0\nepoch-   0 batch number -  180 1.2571194966634114 ACC -  0.0\nepoch-   0 batch number -  210 1.2961006164550781 ACC -  0.0\nepoch-   0 batch number -  240 1.2250829060872397 ACC -  0.0\nepoch-   0 batch number -  270 1.3197568257649739 ACC -  0.0\nepoch-   0 batch number -  300 1.1100274403889974 ACC -  0.0\nepoch-   0 batch number -  330 1.1388284047444661 ACC -  0.0\nepoch-   0 batch number -  360 1.277779261271159 ACC -  0.0\nepoch-   0 batch number -  390 1.2282318115234374 ACC -  0.0\nepoch-   0 batch number -  420 1.1285836537679037 ACC -  0.0\nepoch-   0 batch number -  450 1.2026607513427734 ACC -  0.0\nepoch-   0 batch number -  480 1.2107222239176432 ACC -  0.0\nepoch-   0 batch number -  510 1.3179326375325522 ACC -  0.0\nepoch-   0 batch number -  540 1.198849614461263 ACC -  0.0\nepoch-   0 batch number -  570 1.2944945017496745 ACC -  0.0\nepoch-   0 batch number -  600 1.16757443745931 ACC -  0.0\nepoch-   0 batch number -  630 1.1720911661783855 ACC -  0.0\nepoch-   0 batch number -  660 1.1691279093424478 ACC -  0.0\nepoch-   0 batch number -  690 1.1708446502685548 ACC -  0.0\nepoch-   0 batch number -  720 1.1637709299723307 ACC -  0.0\nepoch-   0 batch number -  750 1.2770983378092449 ACC -  0.0\nepoch-   0 batch number -  780 1.1829666137695312 ACC -  0.0\nepoch-   0 batch number -  810 1.2425582885742188 ACC -  0.0\nepoch-   0 batch number -  840 1.0749520619710287 ACC -  0.0\nepoch-   0 batch number -  870 1.1425287882486979 ACC -  0.0\nepoch-   0 batch number -  900 1.2815903981526693 ACC -  0.0\nepoch-   0 batch number -  930 1.1260332743326822 ACC -  0.0\nepoch-   0 batch number -  960 1.1572587331136068 ACC -  0.0\nepoch-   0 batch number -  990 1.1461118062337239 ACC -  0.0\nepoch-   0 batch number -  1020 1.227173105875651 ACC -  0.0\nepoch-   0 batch number -  1050 1.2843285878499349 ACC -  0.0\nepoch-   0 batch number -  1080 1.1756862640380858 ACC -  0.0\nepoch-   0 batch number -  1110 1.0808113098144532 ACC -  0.0\nepoch-   0 batch number -  1140 1.175586191813151 ACC -  0.0\nepoch-   0 batch number -  1170 1.288821029663086 ACC -  0.0\nepoch-   0 batch number -  1200 1.0937053680419921 ACC -  0.0\nepoch-   0 batch number -  1230 1.2364184061686199 ACC -  0.0\nepoch-   0 batch number -  1260 1.0725995381673177 ACC -  0.0\nepoch-   0 batch number -  1290 1.1966267903645833 ACC -  0.0\nepoch-   0 batch number -  1320 1.1880658467610676 ACC -  0.0\nepoch-   0 batch number -  1350 1.1560264587402345 ACC -  0.0\nepoch-   0 batch number -  1380 1.241918690999349 ACC -  0.0\nepoch-   0 batch number -  1410 1.2594989776611327 ACC -  0.0\nepoch-   0 batch number -  1440 1.1397196451822917 ACC -  0.0\nepoch-   0 batch number -  1470 1.0869888305664062 ACC -  0.0\nepoch-   0 batch number -  1500 1.1914901733398438 ACC -  0.0\nepoch-   0 batch number -  1530 1.1905230204264323 ACC -  0.0\nepoch-   0 batch number -  1560 1.1977612813313803 ACC -  0.0\nepoch-   0 batch number -  1590 1.1944945017496744 ACC -  0.0\nTraining Accuracy -  0.0 Train_loss -  0.03921533044303454 Valid_acc -  0.0 Valid_loss -  tensor(28.0523, device='cuda:0')\nepoch-   1 batch number -  0 1.2231470743815105 ACC -  0.0\nepoch-   1 batch number -  30 1.2630926767985027 ACC -  0.0\nepoch-   1 batch number -  60 1.051103655497233 ACC -  0.0\nepoch-   1 batch number -  90 1.1610711415608723 ACC -  0.0\nepoch-   1 batch number -  120 1.1598888397216798 ACC -  0.0\nepoch-   1 batch number -  150 1.1298501332600912 ACC -  0.0\nepoch-   1 batch number -  180 1.17467409769694 ACC -  0.0\nepoch-   1 batch number -  210 1.1635051727294923 ACC -  0.0\nepoch-   1 batch number -  240 1.1233084360758463 ACC -  0.0\nepoch-   1 batch number -  270 1.127364985148112 ACC -  0.0\nepoch-   1 batch number -  300 1.2293668111165366 ACC -  0.0\nepoch-   1 batch number -  330 1.179683303833008 ACC -  0.0\nepoch-   1 batch number -  360 1.08191769917806 ACC -  0.0\nepoch-   1 batch number -  390 1.1498491923014322 ACC -  0.0\nepoch-   1 batch number -  420 1.1328084309895834 ACC -  0.0\nepoch-   1 batch number -  450 1.0582220077514648 ACC -  0.0\nepoch-   1 batch number -  480 1.179125722249349 ACC -  0.0\nepoch-   1 batch number -  510 1.0442525227864583 ACC -  0.0\nepoch-   1 batch number -  540 1.2105587005615235 ACC -  0.0\nepoch-   1 batch number -  570 1.1875930786132813 ACC -  0.0\nepoch-   1 batch number -  600 1.1930246988932292 ACC -  0.0\nepoch-   1 batch number -  630 1.0276305516560873 ACC -  0.0\nepoch-   1 batch number -  660 1.132925287882487 ACC -  0.0\nepoch-   1 batch number -  690 1.1488995869954428 ACC -  0.0\nepoch-   1 batch number -  720 1.1280189514160157 ACC -  0.0\nepoch-   1 batch number -  750 1.1043593088785808 ACC -  0.0\nepoch-   1 batch number -  780 1.0923473358154296 ACC -  0.0\nepoch-   1 batch number -  810 1.1098634084065755 ACC -  0.0\nepoch-   1 batch number -  840 1.1281144460042318 ACC -  0.0\nepoch-   1 batch number -  870 1.0848743438720703 ACC -  0.0\nepoch-   1 batch number -  900 1.1245287577311198 ACC -  0.0\nepoch-   1 batch number -  930 1.2062033335367839 ACC -  0.0\nepoch-   1 batch number -  960 1.2135850270589192 ACC -  0.0\nepoch-   1 batch number -  990 1.1880912780761719 ACC -  0.0\nepoch-   1 batch number -  1020 1.1734274546305339 ACC -  0.0\nepoch-   1 batch number -  1050 1.0422815958658853 ACC -  0.0\nepoch-   1 batch number -  1080 1.1092383066813152 ACC -  0.0\nepoch-   1 batch number -  1110 1.0519240061442057 ACC -  0.0\nepoch-   1 batch number -  1140 1.1024466196695963 ACC -  0.0\nepoch-   1 batch number -  1170 1.1172294616699219 ACC -  0.0\nepoch-   1 batch number -  1200 1.0712746938069662 ACC -  0.0\nepoch-   1 batch number -  1230 1.21749636332194 ACC -  0.0\nepoch-   1 batch number -  1260 1.1009454091389974 ACC -  0.0\nepoch-   1 batch number -  1290 1.0391501744588216 ACC -  0.0\nepoch-   1 batch number -  1320 1.1513280232747396 ACC -  0.0\nepoch-   1 batch number -  1350 1.1612096150716147 ACC -  0.0\nepoch-   1 batch number -  1380 1.2952816009521484 ACC -  0.0\nepoch-   1 batch number -  1410 1.1836263020833333 ACC -  0.0\nepoch-   1 batch number -  1440 1.0317625681559244 ACC -  0.0\nepoch-   1 batch number -  1470 1.19905637105306 ACC -  0.0\nepoch-   1 batch number -  1500 1.0489405949910482 ACC -  0.0\nepoch-   1 batch number -  1530 1.2134508768717447 ACC -  0.0\nepoch-   1 batch number -  1560 1.1124823252360025 ACC -  0.0\nepoch-   1 batch number -  1590 1.045730717976888 ACC -  0.0\nTraining Accuracy -  0.0 Train_loss -  0.03580577252432705 Valid_acc -  0.0 Valid_loss -  tensor(27.0354, device='cuda:0')\nepoch-   2 batch number -  0 1.091100565592448 ACC -  0.0\nepoch-   2 batch number -  30 1.1609202067057292 ACC -  0.0\nepoch-   2 batch number -  60 1.2761281331380208 ACC -  0.0\nepoch-   2 batch number -  90 1.2022591908772786 ACC -  0.0\nepoch-   2 batch number -  120 1.1349717458089192 ACC -  0.0\nepoch-   2 batch number -  150 1.2605581919352213 ACC -  0.0\nepoch-   2 batch number -  180 1.0909741719563801 ACC -  0.0\nepoch-   2 batch number -  210 1.2085978190104167 ACC -  0.0\nepoch-   2 batch number -  240 1.074941889444987 ACC -  0.0\nepoch-   2 batch number -  270 1.1271191914876302 ACC -  0.0\nepoch-   2 batch number -  300 1.2197270711263022 ACC -  0.0\nepoch-   2 batch number -  330 1.112286122639974 ACC -  0.0\nepoch-   2 batch number -  360 1.160408655802409 ACC -  0.0\nepoch-   2 batch number -  390 1.080849838256836 ACC -  0.0\nepoch-   2 batch number -  420 1.1110698699951171 ACC -  0.0\nepoch-   2 batch number -  450 1.1731426239013671 ACC -  0.0\nepoch-   2 batch number -  480 1.1370835622151694 ACC -  0.0\nepoch-   2 batch number -  510 1.162610371907552 ACC -  0.0\nepoch-   2 batch number -  540 1.0682633717854817 ACC -  0.0\nepoch-   2 batch number -  570 1.1029412587483725 ACC -  0.0\nepoch-   2 batch number -  600 0.9614274342854817 ACC -  0.0\nepoch-   2 batch number -  630 1.0982755025227864 ACC -  0.0\nepoch-   2 batch number -  660 1.1149431864420574 ACC -  0.0\nepoch-   2 batch number -  690 1.0406614939371746 ACC -  0.0\nepoch-   2 batch number -  720 1.0308897018432617 ACC -  0.0\nepoch-   2 batch number -  750 1.1390996297200522 ACC -  0.0\nepoch-   2 batch number -  780 1.14036013285319 ACC -  0.0\nepoch-   2 batch number -  810 0.960097058614095 ACC -  0.0\nepoch-   2 batch number -  840 1.0597622553507486 ACC -  0.0\nepoch-   2 batch number -  870 1.1572034200032553 ACC -  0.0\nepoch-   2 batch number -  900 1.1004299163818358 ACC -  0.0\nepoch-   2 batch number -  930 1.1741238911946614 ACC -  0.0\nepoch-   2 batch number -  960 1.1170706431070963 ACC -  0.0\nepoch-   2 batch number -  990 1.0631742477416992 ACC -  0.0\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_data_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[69], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(parameters, encoder, decoder, train_data, valid_data, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m encoder_opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     39\u001b[0m decoder_opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 40\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m encoder_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m decoder_opt\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}