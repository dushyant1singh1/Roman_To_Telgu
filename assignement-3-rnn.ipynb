{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8239567,"sourceType":"datasetVersion","datasetId":4887607},{"sourceId":8315756,"sourceType":"datasetVersion","datasetId":4939658}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport torch\nimport os\nimport pandas as pd\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\nimport random\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-17T17:15:05.713611Z","iopub.execute_input":"2024-05-17T17:15:05.714209Z","iopub.status.idle":"2024-05-17T17:15:05.720835Z","shell.execute_reply.started":"2024-05-17T17:15:05.714174Z","shell.execute_reply":"2024-05-17T17:15:05.719697Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"for dirname, _ ,filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname,filename))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:06.724870Z","iopub.execute_input":"2024-05-17T17:15:06.725303Z","iopub.status.idle":"2024-05-17T17:15:06.749974Z","shell.execute_reply.started":"2024-05-17T17:15:06.725271Z","shell.execute_reply":"2024-05-17T17:15:06.748681Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/roman-to-telgu/tel_test.csv\n/kaggle/input/roman-to-telgu/tel_valid.csv\n/kaggle/input/roman-to-telgu/tel_train.csv\n/kaggle/input/roman-to-hindi/hin_valid.csv\n/kaggle/input/roman-to-hindi/hin_test.csv\n/kaggle/input/roman-to-hindi/hin_train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:06.992994Z","iopub.execute_input":"2024-05-17T17:15:06.993407Z","iopub.status.idle":"2024-05-17T17:15:07.000204Z","shell.execute_reply.started":"2024-05-17T17:15:06.993374Z","shell.execute_reply":"2024-05-17T17:15:06.998832Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"class Hyperparameters:\n    def __init__(self,input_dim:int,output_dim:int,\n                 encoder_layers =1,decoder_layers=1,hidden_size=64,embed_dim=512,num_layers=1\n                 ,cell_type:str='rnn',bidirectional:bool=False,dropout:float=0,beam_search:int=0,\n                 learning_rate=0.001):\n        self.encoder_layers = encoder_layers\n        self.decoder_layers = decoder_layers\n        self.hidden_size = hidden_size\n        #input_dim is size of vocabulary of input language\n        self.input_dim = input_dim\n        self.embed_dim = embed_dim\n        self.num_layers = num_layers\n        #output_dim is size of vocabulary of output language\n        self.output_dim = output_dim\n    \n        cell_dict = {'rnn':nn.RNN,'gru':nn.GRU,'lstm':nn.LSTM}\n        self.cell = cell_dict[cell_type]\n        self.cell_name = cell_type\n        self.bidirectional = bidirectional\n        self.dropout = dropout\n        self.beam_search = beam_search\n        self.learning_rate = learning_rate","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:08.024344Z","iopub.execute_input":"2024-05-17T17:15:08.024974Z","iopub.status.idle":"2024-05-17T17:15:08.034285Z","shell.execute_reply.started":"2024-05-17T17:15:08.024942Z","shell.execute_reply":"2024-05-17T17:15:08.032857Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# parameters - this class contains all the configurations for the model\nclass EncoderRNN(nn.Module):\n    def __init__(self,parameters:Hyperparameters):\n        super(EncoderRNN,self).__init__()\n        # hidden_dim - number of the neuron in the hidden state\n        self.hidden_dim = parameters.hidden_size\n        # num_layers - number of the layers in the encoder\n        self.num_layers = parameters.encoder_layers\n        # parameters.embedding - size of the embedding vector\n        # parameters.input_dim - size of the vocabulary dictionary\n        self.embedding = nn.Embedding(parameters.input_dim,parameters.embed_dim,padding_idx = 2)\n        # parameters.cell - the type of cell : RNN, LSTM, GRU\n        self.cell_name = parameters.cell\n        self.dropout = nn.Dropout(parameters.dropout)\n        self.cell = parameters.cell(parameters.embed_dim,parameters.hidden_size,num_layers=self.num_layers,batch_first=True, dropout=parameters.dropout)\n        #batch_first=False, dropout=0.0, bidirectional=False\n    \n    def forward(self,input_data,h_0):\n        \n        embedded = self.embedding(input_data)\n        embedded = self.dropout(embedded)\n        output, hidden = self.cell(embedded,h_0)\n        return output,hidden\n\n    def hidden_initializer(self,batch_size):\n        return torch.zeros(self.num_layers,batch_size,self.hidden_dim,device = device)\n    \nclass DecoderRNN(nn.Module):\n    def __init__(self,parameters:Hyperparameters):\n        super(DecoderRNN,self).__init__()\n        # hidden_dim - number of neurons in the hidden state\n        self.hidden_dim = parameters.hidden_size\n        # num_layers - number of decoder layers\n        self.num_layers = parameters.decoder_layers\n        # cell_name - LSTM, GRU, RNN\n        self.cell_name = parameters.cell\n        self.embedding = nn.Embedding(parameters.output_dim,parameters.embed_dim)\n        self.dropout = nn.Dropout(parameters.dropout)\n        self.cell = parameters.cell(parameters.embed_dim,self.hidden_dim,num_layers=self.num_layers,batch_first=True, dropout=parameters.dropout)\n        self.out = nn.Linear(parameters.hidden_size,parameters.output_dim)\n        self.softmax = nn.LogSoftmax(dim=2)\n        \n    def forward(self,input_data,h_0):\n        embedded = self.embedding(input_data)\n        activation = F.relu(embedded)\n        activation = self.dropout(activation)\n        output, hidden = self.cell(activation, h_0)\n        output = self.softmax(self.out(output))\n        return output,hidden","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:08.717145Z","iopub.execute_input":"2024-05-17T17:15:08.717704Z","iopub.status.idle":"2024-05-17T17:15:08.738325Z","shell.execute_reply.started":"2024-05-17T17:15:08.717673Z","shell.execute_reply":"2024-05-17T17:15:08.737108Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\nPAD_token = 2\ndef characterFetching(x):\n    characters = 3\n    ind2ch ={SOS_token:'<',EOS_token:'>',PAD_token:'_'}\n    ch2ind ={'<':SOS_token,'>':EOS_token,'_':PAD_token}\n    for word in x:\n        for letter in word:\n            if letter not in ch2ind:\n                ch2ind[letter] = characters\n                ind2ch[characters] = letter\n                characters+=1\n    return [ch2ind,ind2ch,characters]\ndef wordPairs(x,y):\n    return [[x[i],y[i]] for i in range(len(x))]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:09.142492Z","iopub.execute_input":"2024-05-17T17:15:09.143000Z","iopub.status.idle":"2024-05-17T17:15:09.151676Z","shell.execute_reply.started":"2024-05-17T17:15:09.142959Z","shell.execute_reply":"2024-05-17T17:15:09.150315Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def dataLoading(data_type):\n    path = \"/kaggle/input/roman-to-telgu/tel_{}.csv\".format(data_type)\n    df = pd.read_csv(path,header=None)\n    return df[0].to_numpy(), df[1].to_numpy()    ","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:09.502089Z","iopub.execute_input":"2024-05-17T17:15:09.502476Z","iopub.status.idle":"2024-05-17T17:15:09.509103Z","shell.execute_reply.started":"2024-05-17T17:15:09.502447Z","shell.execute_reply":"2024-05-17T17:15:09.507817Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_input_data, train_output_data = dataLoading('train')\nval_input_data, val_output_data = dataLoading('valid')","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:10.607314Z","iopub.execute_input":"2024-05-17T17:15:10.607714Z","iopub.status.idle":"2024-05-17T17:15:10.787549Z","shell.execute_reply.started":"2024-05-17T17:15:10.607683Z","shell.execute_reply":"2024-05-17T17:15:10.786584Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(train_input_data,train_output_data)\nprint(val_input_data, val_output_data )","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:11.604374Z","iopub.execute_input":"2024-05-17T17:15:11.604831Z","iopub.status.idle":"2024-05-17T17:15:11.612013Z","shell.execute_reply.started":"2024-05-17T17:15:11.604794Z","shell.execute_reply":"2024-05-17T17:15:11.610499Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['vargaalavaarine' 'vastadira' 'factamfos' ... 'venakkiteesukoovaalane'\n 'roopaantaraalu' 'chendindindi'] ['వర్గాలవారినే' 'వస్తాదిరా' 'ఫ్యాక్టమ్ఫోస్' ... 'వెనక్కితీసుకోవాలనే'\n 'రూపాంతరాలు' 'చెందిందింది']\n['bheeshmudini' 'vinyasaanni' 'kaavachhunu' ... 'asramam' 'divine' 'dis'] ['భీష్ముడిని' 'విన్యాసాన్ని' 'కావచ్చును' ... 'ఆశ్రమం' 'డివైన్' 'డిస్']\n","output_type":"stream"}]},{"cell_type":"code","source":"#train_en, train_hin, valid_en and valid_hin all are list of length 3\n# 0 index contain dictionary for characters to index\n# 1 index contain dictionary for index to characters\n# 2 index contain number of unique characters \n# en - english and hin - hindi\n# train - training data , valid - validation data\ntrain_en = characterFetching(train_input_data)\ntrain_tel = characterFetching(train_output_data)\ntrain_wordpairs = wordPairs(train_input_data,train_output_data)\nvalid_wordpairs = wordPairs(val_input_data,val_output_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:12.568345Z","iopub.execute_input":"2024-05-17T17:15:12.568760Z","iopub.status.idle":"2024-05-17T17:15:12.854825Z","shell.execute_reply.started":"2024-05-17T17:15:12.568715Z","shell.execute_reply":"2024-05-17T17:15:12.853500Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(train_en[2])\nprint(train_tel[2])","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:13.837544Z","iopub.execute_input":"2024-05-17T17:15:13.837983Z","iopub.status.idle":"2024-05-17T17:15:13.844649Z","shell.execute_reply.started":"2024-05-17T17:15:13.837949Z","shell.execute_reply":"2024-05-17T17:15:13.843479Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"29\n65\n","output_type":"stream"}]},{"cell_type":"code","source":"#input_t and output_t are I have stored character to index dictionary and one pair is given\ndef mannualPadding(x,padding_index,max_length):\n    length_of_padding = max_length - len(x)\n    padded_list = [padding_index]*(length_of_padding)\n    x.extend(padded_list)\n    return x\ndef gettingTensorFromPair(pair,input_t,output_t,padding_index,max_length):\n    word_en = pair[0]\n    word_tel = pair[1]\n    indexes_en = [input_t[char] for char in word_en]\n    indexes_tel = [output_t[char] for char in word_tel]\n    indexes_en.append(EOS_token)\n    indexes_tel.append(EOS_token)\n    \n    indexes_en = mannualPadding(indexes_en,padding_index,max_length)\n    indexes_tel = mannualPadding(indexes_tel,padding_index,max_length)\n    \n    input_tensor = torch.tensor(indexes_en,dtype=torch.long,device=device)\n    output_tensor = torch.tensor(indexes_tel,dtype=torch.long,device=device)\n    return input_tensor,output_tensor","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:14.865569Z","iopub.execute_input":"2024-05-17T17:15:14.865987Z","iopub.status.idle":"2024-05-17T17:15:14.875660Z","shell.execute_reply.started":"2024-05-17T17:15:14.865957Z","shell.execute_reply":"2024-05-17T17:15:14.874679Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nBATCH_SIZE = 32\nMAX_LENGTH = 30\ntrain_data = [gettingTensorFromPair(pair,train_en[0],train_tel[0],2,MAX_LENGTH) for pair in train_wordpairs]\nval_data = [gettingTensorFromPair(pair,train_en[0],train_tel[0],2,MAX_LENGTH) for pair in valid_wordpairs]\n\n# train_input_tensors , train_output_tensors = [pair[0] for pair in train_data ],[pair[1] for pair in train_data]\n# val_input_tensors, val_output_tensors = [pair[0] for pair in val_data], [pair[1] for pair in val_data]\n\ntrain_data = DataLoader(train_data,batch_size=BATCH_SIZE,shuffle= True)\nvalid_data = DataLoader(val_data,batch_size = BATCH_SIZE,shuffle = True)\n\n# train_input_loader = DataLoader(train_input_tensors,BATCH_SIZE)\n# train_output_loader = dataLoader(train_output_tensors,BATCH_SIZE)\n# val_input_loader = dataLoader(val_input_tensors,BATCH_SIZE)\n# val_output_loader = dataLoader(val_output_tensors,BATCH_SIZE)\n# valid_data = [val_input_loader,val_output_loader]","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:15.710845Z","iopub.execute_input":"2024-05-17T17:15:15.713157Z","iopub.status.idle":"2024-05-17T17:15:17.607690Z","shell.execute_reply.started":"2024-05-17T17:15:15.713077Z","shell.execute_reply":"2024-05-17T17:15:17.606378Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for input_t, labels in train_data:\n    print(input_t.size())\n    for word in input_t:\n        print([train_en[1][char.item()] for char in word])\n        break\n    for word in labels:\n        print([train_tel[1][char.item()] for char in word])\n        break\n    print(labels.size())\n    break","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:19.210620Z","iopub.execute_input":"2024-05-17T17:15:19.211053Z","iopub.status.idle":"2024-05-17T17:15:19.279640Z","shell.execute_reply.started":"2024-05-17T17:15:19.211020Z","shell.execute_reply":"2024-05-17T17:15:19.278359Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"torch.Size([32, 30])\n['m', 'a', 'r', 'u', 'v', 'a', 'd', 'd', 'u', '>', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n['మ', 'ర', 'ు', 'వ', 'ద', '్', 'ద', 'ు', '>', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\ntorch.Size([32, 30])\n","output_type":"stream"}]},{"cell_type":"code","source":"def printingString(predicted_sequences,output_tensor,input_tensor,type_of_data):\n    \n    if type_of_data=='train':\n        for i in range(5):\n            predicted_string = \"\"\n            target_string =\"\"\n            input_string =\"\"\n            for j in range(predicted_sequences.size(1)):\n                predicted_string += train_tel[1][predicted_sequences[i,j].item()]\n                target_string += train_tel[1][output_tensor[i,j].item()]\n                input_string += train_en[1][input_tensor[i,j].item()]\n            print(\"{} {} {}\".format(predicted_string,target_string,input_string))\n    else:\n        for i in range(5):\n            predicted_string = \"\"\n            target_string =\"\"\n            input_string =\"\"\n            for j in range(predicted_sequences.size(1)):\n                predicted_string += train_tel[1][predicted_sequences[i,j].item()]\n                target_string += train_tel[1][output_tensor[i,j].item()]\n                input_string += train_en[1][input_tensor[i,j].item()]\n            print(\"{} {} {}\".format(predicted_string,target_string,input_string))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:20.320418Z","iopub.execute_input":"2024-05-17T17:15:20.320943Z","iopub.status.idle":"2024-05-17T17:15:20.335678Z","shell.execute_reply.started":"2024-05-17T17:15:20.320904Z","shell.execute_reply":"2024-05-17T17:15:20.334326Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def accuracy(para,encoder,decoder,data,batch_size,type_of_data):\n    encoder.eval()\n    decoder.eval()\n    criterion = nn.NLLLoss()\n    correct_predictions =0 \n    total=0\n    total_loss =0\n    batch_length = len(data)\n    with torch.no_grad():\n        for input_batch , output_batch in data:\n            loss = 0\n            \n            #predicted_string_index = torch.zeros(input_data.size(1),batch_size,1)\n            \n            input_tensor = input_batch.to(device)\n            output_tensor = output_batch.to(device)\n            \n            encoder_hidden = encoder.hidden_initializer(batch_size)\n            if para.cell_name=='lstm':\n                encoder_hidden = (encoder_hidden,encoder.hidden_initializer(batch_size))\n                \n            output_length = output_tensor.size(0)\n            \n            encoder_out , encoder_hidden = encoder(input_tensor,encoder_hidden)\n                \n            decoder_input = torch.full((batch_size,1),SOS_token,device = device)\n            #print(decoder_input.size())\n            #print(output_tensor.size())\n            decoder_hidden = encoder_hidden\n            predicted_sequences = []\n            for j in range(output_batch.size(1)):\n                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n                loss+= criterion(decoder_output[:,-1,:],output_tensor[:,j])\n                # Get predicted tokens\n                _, topi = decoder_output.topk(1)\n                predicted_sequences.append(topi.squeeze().tolist())\n                \n                # Use predicted token as next input\n                decoder_input = topi.squeeze().detach().view(batch_size,1)\n            total_loss += loss.item()/output_tensor.size(1)\n            # Convert predicted sequences to tensors\n            predicted_sequences = torch.transpose(torch.tensor(predicted_sequences),0,1).to(device)\n           # make_string(predicted_sequences,output_tensor,input_tensor,type_of_data)\n            # Compare predicted sequences with target sequences\n            correct_predictions += torch.sum((predicted_sequences == output_tensor).all(dim=1)).item()\n            total += batch_size\n        return correct_predictions/total, total_loss/batch_length","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:21.367527Z","iopub.execute_input":"2024-05-17T17:15:21.367920Z","iopub.status.idle":"2024-05-17T17:15:21.381561Z","shell.execute_reply.started":"2024-05-17T17:15:21.367891Z","shell.execute_reply":"2024-05-17T17:15:21.380697Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def train(encoder:EncoderRNN,decoder:DecoderRNN,epochs:int,para:Hyperparameters,train_data,valid_data,batch_size,teacher_forcing_ratio):\n    encoder_opt = optim.Adam(encoder.parameters(),para.learning_rate)\n    decoder_opt = optim.Adam(decoder.parameters(),para.learning_rate)\n    criterion = nn.NLLLoss()\n    total_batches = len(train_data)\n    for epch in range(epochs):\n        total_loss = 0 \n        encoder.train()\n        decoder.train()\n        for ind, (input_tensor, output_tensor) in enumerate(tqdm(train_data, desc=f'Training Progress {epch+1}')):\n       # for input_tensor, output_tensor in zip(input_t,output_t):\n            encoder_opt.zero_grad()\n            decoder_opt.zero_grad()\n            \n            input_length = input_tensor.size(0)\n            output_length = output_tensor.size(0)\n            \n            input_tensor = input_tensor.to(device)\n            output_tensor = output_tensor.to(device)\n            # D*num_layers , batch_size, number of neurons in hidden layer\n            encoder_hidden = encoder.hidden_initializer(batch_size)\n            if para.cell_name=='lstm':\n                   encoder_hidden = (encoder_hidden, encoder.hidden_initializer(batch_size))\n            \n            loss =0\n            encoder_out , encoder_hidden = encoder(input_tensor,encoder_hidden)\n                \n            #decoder_input = torch.full((batch_size,1),SOS_token,device = device)\n            decoder_input = output_tensor[:,0].view(batch_size,1)\n            \n            decoder_hidden = encoder_hidden\n\n            teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n#             if teacher_forcing:\n#                 for j in range(output_tensor.size(1)):\n                    \n#                     decoder_out, decoder_hidden = decoder(decoder_input, decoder_hidden)\n#                     loss+= criterion(decoder_out[:,-1,:],output_tensor[:,j])\n#                     decoder_input = output_tensor[:,j].unsqueeze(1)\n#             else:\n#                 for j in range(output_tensor.size(1)):\n#                     decoder_out, decoder_hidden = decoder(decoder_input,decoder_hidden)\n#                     #decoder.size = batch size , sequence length, output vocabulry size\n#                     loss += criterion(decoder_out[:,-1,:], output_tensor[:, j])\n#                     topv, topi = decoder_out.topk(1)\n                    \n#                     decoder_input = topi.squeeze().detach().view(batch_size,1)\n            for j in range(output_tensor.size(1)):\n                decoder_out, decoder_hidden = decoder(decoder_input,decoder_hidden)\n                topv, topi = decoder_out.topk(1)\n                decoder_input = topi.squeeze().detach().view(batch_size,1)\n                loss+=criterion(decoder_out[:,-1,:],output_tensor[:,j])\n                if(j<output_tensor.size(1)-1):\n                    if teacher_forcing:\n                        decoder_input = output_tensor[:,j+1].view(batch_size,1)\n    \n            total_loss += loss.item()/output_tensor.size(1)\n            loss.backward()\n            encoder_opt.step()\n            decoder_opt.step()\n   #     train_acc, train_loss = accuracy(para,encoder,decoder,train_data,batch_size,'train')\n        val_acc, val_loss = accuracy(para,encoder,decoder,valid_data,batch_size,'valid')\n        print(\"Training accuracy for epoch {} is, and loss - {}\".format((epch+1),total_loss/total_batches))\n        print(\"Validation accuracy is - {} and loss -{}\".format(val_acc,val_loss))","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:22.114314Z","iopub.execute_input":"2024-05-17T17:15:22.115367Z","iopub.status.idle":"2024-05-17T17:15:22.133511Z","shell.execute_reply.started":"2024-05-17T17:15:22.115330Z","shell.execute_reply":"2024-05-17T17:15:22.132144Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"parameters = Hyperparameters(input_dim=train_en[2],output_dim=train_tel[2],encoder_layers = 15,decoder_layers =15,cell_type='lstm',bidirectional=True,hidden_size = 256)\nencoder = EncoderRNN(parameters).to(device)\ndecoder = DecoderRNN(parameters).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:22.952189Z","iopub.execute_input":"2024-05-17T17:15:22.952554Z","iopub.status.idle":"2024-05-17T17:15:23.173228Z","shell.execute_reply.started":"2024-05-17T17:15:22.952525Z","shell.execute_reply":"2024-05-17T17:15:23.172196Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train(encoder,decoder,20,parameters,train_data,valid_data,batch_size=BATCH_SIZE,teacher_forcing_ratio=0.5)","metadata":{"execution":{"iopub.status.busy":"2024-05-17T17:15:23.921232Z","iopub.execute_input":"2024-05-17T17:15:23.921647Z","iopub.status.idle":"2024-05-17T17:15:31.781487Z","shell.execute_reply.started":"2024-05-17T17:15:23.921615Z","shell.execute_reply":"2024-05-17T17:15:31.779814Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Training Progress 1:   0%|          | 0/1600 [00:04<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalid_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[18], line 58\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, epochs, para, train_data, valid_data, batch_size, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     55\u001b[0m             decoder_input \u001b[38;5;241m=\u001b[39m output_tensor[:,j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mview(batch_size,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     57\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m/\u001b[39moutput_tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m encoder_opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     60\u001b[0m decoder_opt\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# import gc\n# encoder = None\n# decoder = None\n# gc.collect()\n# torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T14:01:04.668602Z","iopub.execute_input":"2024-04-29T14:01:04.669305Z","iopub.status.idle":"2024-04-29T14:01:04.883933Z","shell.execute_reply.started":"2024-04-29T14:01:04.669275Z","shell.execute_reply":"2024-04-29T14:01:04.882708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}